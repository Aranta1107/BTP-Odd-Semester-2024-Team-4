{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6aee3286d04f4053a4a0a2b3c620f847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31b32a0dce10452e841d18da38db2715",
              "IPY_MODEL_910c3ed5fc0c4edba6b041c1541f866f",
              "IPY_MODEL_5e6016114c2a4542b9828743fcd21889"
            ],
            "layout": "IPY_MODEL_19198321c52c4bef9fbaa77479787535"
          }
        },
        "31b32a0dce10452e841d18da38db2715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc033035b6bd4582b9e12b0d0760f748",
            "placeholder": "​",
            "style": "IPY_MODEL_3d62496ea4bd4642bce5bdc1f8fd7034",
            "value": "Map: 100%"
          }
        },
        "910c3ed5fc0c4edba6b041c1541f866f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a9653fe657643539c05251cee6295b9",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_110da91eedd1404f94a8788f021ab435",
            "value": 3
          }
        },
        "5e6016114c2a4542b9828743fcd21889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a60660be0e948d4ad7075848a8e8b22",
            "placeholder": "​",
            "style": "IPY_MODEL_0a586adfd2184e7b8b0ebe1d1da29a21",
            "value": " 3/3 [00:00&lt;00:00, 76.93 examples/s]"
          }
        },
        "19198321c52c4bef9fbaa77479787535": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc033035b6bd4582b9e12b0d0760f748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d62496ea4bd4642bce5bdc1f8fd7034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a9653fe657643539c05251cee6295b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "110da91eedd1404f94a8788f021ab435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a60660be0e948d4ad7075848a8e8b22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a586adfd2184e7b8b0ebe1d1da29a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef425fa04a4e4483ac39f9532ed7848a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30da68909f5c4452bdff461dab833e98",
              "IPY_MODEL_d1c6ac28944448deb825ebedb0986549",
              "IPY_MODEL_ed304b42534646fea1d73060fe84206f"
            ],
            "layout": "IPY_MODEL_999687d5432f49c6afeab05602056e70"
          }
        },
        "30da68909f5c4452bdff461dab833e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cccc68ac13c74a31ba362e111e8a873c",
            "placeholder": "​",
            "style": "IPY_MODEL_232c30df3360463ca05cb2c706d8b4d1",
            "value": "Map: 100%"
          }
        },
        "d1c6ac28944448deb825ebedb0986549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c704fbd278b47d3b66be63d790684ae",
            "max": 520,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eed1abc400da49e6bd2f590e674847b5",
            "value": 520
          }
        },
        "ed304b42534646fea1d73060fe84206f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4524a10e2f764ca98c7c77d69bfb9d6d",
            "placeholder": "​",
            "style": "IPY_MODEL_dccad691c80049368ca56bca7327d62f",
            "value": " 520/520 [00:00&lt;00:00, 1954.08 examples/s]"
          }
        },
        "999687d5432f49c6afeab05602056e70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cccc68ac13c74a31ba362e111e8a873c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "232c30df3360463ca05cb2c706d8b4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c704fbd278b47d3b66be63d790684ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eed1abc400da49e6bd2f590e674847b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4524a10e2f764ca98c7c77d69bfb9d6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dccad691c80049368ca56bca7327d62f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BhaashikTantraE2EPrototype: Translation for Low-Resource Indic Languages\n",
        "\n",
        "This notebook demonstrates the end-to-end process of loading a tokenizer, preparing datasets, fine-tuning pretrained models, translating texts, and evaluating the results using the BhaashikTantraE2EPrototype library.\n",
        "\n",
        "\n",
        "This notebook provides a comprehensive setup for Google Colab to facilitate the end-to-end workflow for machine translation with BhaashikTantraE2EPrototype. You can copy the above cells into a Jupyter notebook file (`.ipynb`) and run them in Google Colab. Make sure to adapt paths and hyperparameters to your specific requirements!"
      ],
      "metadata": {
        "id": "FNO9tWhHKyTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Please run the cells below to install the necessary dependencies."
      ],
      "metadata": {
        "id": "Pv16hSAJGBp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets sacrebleu peft indic-nlp-library"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNJZUaad3_GR",
        "outputId": "00b6a989-6496-45e0-b554-c30b1b448139"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.3)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: indic-nlp-library in /usr/local/lib/python3.10/dist-packages (0.92)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (3.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.9.11)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.46.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.1.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
            "Requirement already satisfied: sphinx-argparse in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (0.5.2)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (3.0.2)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (2.0.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from sphinx-argparse->indic-nlp-library) (8.1.3)\n",
            "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.10/dist-packages (from sphinx-argparse->indic-nlp-library) (0.21.2)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (4.1)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.20.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.18.0)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.16.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: tomli>=2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/VarunGumma/IndicTransToolkit.git\n",
        "%cd IndicTransToolkit\n",
        "!python3 -m pip install --editable ./\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xklho0O74mKP",
        "outputId": "ea14a043-1a71-47e5-9826-e4c7fde9f194"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'IndicTransToolkit' already exists and is not an empty directory.\n",
            "/content/IndicTransToolkit\n",
            "Obtaining file:///content/IndicTransToolkit\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library (from IndicTransToolkit==1.0.2)\n",
            "  Cloning https://github.com/VarunGumma/indic_nlp_library to /tmp/pip-install-k23x4gm8/indic-nlp-library-it2_234dd9d25da0495aa5adc57506742261\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/VarunGumma/indic_nlp_library /tmp/pip-install-k23x4gm8/indic-nlp-library-it2_234dd9d25da0495aa5adc57506742261\n",
            "  Resolved https://github.com/VarunGumma/indic_nlp_library to commit 601521e05ed0ed8f2165ac317a47d186e25b6f0d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from IndicTransToolkit==1.0.2) (75.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from IndicTransToolkit==1.0.2) (2.5.1+cu121)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from IndicTransToolkit==1.0.2) (0.1.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from IndicTransToolkit==1.0.2) (0.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from IndicTransToolkit==1.0.2) (4.46.2)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (from IndicTransToolkit==1.0.2) (2.4.3)\n",
            "Requirement already satisfied: sphinx-argparse in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (0.5.2)\n",
            "Requirement already satisfied: sphinx_rtd_theme in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (3.0.2)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.0.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (1.26.4)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu->IndicTransToolkit==1.0.2) (3.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->IndicTransToolkit==1.0.2) (2024.9.11)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->IndicTransToolkit==1.0.2) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu->IndicTransToolkit==1.0.2) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->IndicTransToolkit==1.0.2) (5.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->IndicTransToolkit==1.0.2) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->IndicTransToolkit==1.0.2) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses->IndicTransToolkit==1.0.2) (4.66.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransToolkit==1.0.2) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransToolkit==1.0.2) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransToolkit==1.0.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransToolkit==1.0.2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransToolkit==1.0.2) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransToolkit==1.0.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->IndicTransToolkit==1.0.2) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransToolkit==1.0.2) (0.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransToolkit==1.0.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransToolkit==1.0.2) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransToolkit==1.0.2) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransToolkit==1.0.2) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransToolkit==1.0.2) (0.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->IndicTransToolkit==1.0.2) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->IndicTransToolkit==1.0.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->IndicTransToolkit==1.0.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->IndicTransToolkit==1.0.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->IndicTransToolkit==1.0.2) (2024.8.30)\n",
            "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (8.1.3)\n",
            "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.10/dist-packages (from sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (0.21.2)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.10/dist-packages (from sphinx_rtd_theme->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (1.16.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.0.0)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.18.0)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.16.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (1.4.1)\n",
            "Requirement already satisfied: tomli>=2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.1.0)\n",
            "Installing collected packages: IndicTransToolkit\n",
            "  Attempting uninstall: IndicTransToolkit\n",
            "    Found existing installation: IndicTransToolkit 1.0.2\n",
            "    Uninstalling IndicTransToolkit-1.0.2:\n",
            "      Successfully uninstalled IndicTransToolkit-1.0.2\n",
            "  Running setup.py develop for IndicTransToolkit\n",
            "Successfully installed IndicTransToolkit-1.0.2\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANT : Restart your run-time first and then run the cells below.**"
      ],
      "metadata": {
        "id": "TB5V_0u_IEVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries and Initialize Metrics\n",
        "\n",
        "This section of the notebook imports the required libraries and initializes evaluation metrics for fine-tuning and evaluating the IndicTrans2 model.\n",
        "\n",
        "### Libraries Imported\n",
        "1. **General-purpose libraries**:\n",
        "   - `os`: For file path operations.\n",
        "   - `argparse`: For parsing command-line arguments.\n",
        "\n",
        "2. **Data handling and metrics**:\n",
        "   - `pandas`: For data manipulation.\n",
        "   - `datasets.Dataset`: For working with Hugging Face-compatible datasets.\n",
        "   - `sacrebleu.metrics.BLEU`: To evaluate translation quality using the BLEU metric.\n",
        "   - `sacrebleu.metrics.CHRF`: To evaluate translation quality using the CHRF metric.\n",
        "\n",
        "3. **Model fine-tuning**:\n",
        "   - `peft`: For applying parameter-efficient fine-tuning using LoRA (Low-Rank Adaptation).\n",
        "\n",
        "4. **Indic language processing**:\n",
        "   - `IndicTransToolkit`: For processing and handling Indic language data.\n",
        "\n",
        "5. **Hugging Face Transformers**:\n",
        "   - `Seq2SeqTrainer`: For training sequence-to-sequence models.\n",
        "   - `Seq2SeqTrainingArguments`: For defining training configurations.\n",
        "   - `AutoModelForSeq2SeqLM`: For loading pre-trained sequence-to-sequence models.\n",
        "   - `AutoTokenizer`: For tokenizing text data.\n",
        "   - `EarlyStoppingCallback`: For stopping training early when validation loss stops improving.\n",
        "\n",
        "### Metric Initialization\n",
        "- **BLEU Metric**: Initialized with `BLEU()` from `sacrebleu`.\n",
        "- **CHRF Metric**: Initialized with `CHRF()` from `sacrebleu`.\n",
        "\n",
        "### Notes\n",
        "- Ensure all libraries are installed before executing this cell. Install missing packages using the following commands:\n",
        "  ```bash\n",
        "  pip install pandas datasets sacrebleu peft IndicTransToolkit transformers\n"
      ],
      "metadata": {
        "id": "PlmUgkE9IaZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F4xFZ9WB358h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from sacrebleu.metrics import BLEU, CHRF\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from IndicTransToolkit import IndicProcessor, IndicDataCollator\n",
        "from transformers import (\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    EarlyStoppingCallback,\n",
        ")\n",
        "\n",
        "bleu_metric = BLEU()\n",
        "chrf_metric = CHRF()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Loading, Preprocessing, and Evaluation\n",
        "\n",
        "This section defines functions to load and preprocess the translation dataset, compute evaluation metrics, and tokenize input data for the model.\n",
        "\n",
        "---\n",
        "\n",
        "### `load_and_process_translation_dataset`\n",
        "**Purpose**:  \n",
        "Load a parallel dataset for translation, preprocess it, and tokenize it for model training.\n",
        "\n",
        "**Parameters**:\n",
        "- `data_dir` (str): Path to the directory containing the dataset.\n",
        "- `split` (str): Data split to use (`train`, `val`, or `test`).\n",
        "- `tokenizer`: Tokenizer object to process text data.\n",
        "- `processor`: Instance of `IndicProcessor` for Indic-specific preprocessing.\n",
        "- `src_lang_list` (list): List of source languages.\n",
        "- `tgt_lang_list` (list): List of target languages.\n",
        "- `num_proc` (int): Number of parallel processes for tokenization.\n",
        "- `seed` (int): Random seed for dataset shuffling.\n",
        "\n",
        "**Functionality**:\n",
        "1. Constructs paths for source and target language files.\n",
        "2. Reads and validates the number of lines in source and target files.\n",
        "3. Preprocesses text using the `processor` object.\n",
        "4. Converts the dataset into a Hugging Face `Dataset` and tokenizes it.\n",
        "\n",
        "**Returns**:  \n",
        "A tokenized and shuffled `Dataset` object ready for training.\n",
        "\n",
        "**Notes**:\n",
        "- Raises `FileNotFoundError` if source or target files are missing.\n",
        "- Ensures source and target files have the same number of lines.\n",
        "\n",
        "---\n",
        "\n",
        "### `compute_metrics_factory`\n",
        "**Purpose**:  \n",
        "Factory function to create a metric computation function for evaluating translation quality.\n",
        "\n",
        "**Parameters**:\n",
        "- `tokenizer`: Tokenizer used to decode model predictions.\n",
        "- `metric_dict` (dict): Dictionary of metric objects (e.g., BLEU, CHRF).\n",
        "- `print_samples` (bool): Whether to print a sample of predictions and references.\n",
        "- `n_samples` (int): Number of samples to print if `print_samples` is `True`.\n",
        "\n",
        "**Functionality**:\n",
        "1. Decodes predictions and references into human-readable text.\n",
        "2. Computes evaluation metrics (e.g., BLEU, CHRF) on the predictions.\n",
        "3. Optionally prints a random sample of predictions and their corresponding references.\n",
        "\n",
        "**Returns**:  \n",
        "A dictionary containing the scores for each metric.\n",
        "\n",
        "---\n",
        "\n",
        "### `preprocess_fn`\n",
        "**Purpose**:  \n",
        "Tokenize source and target text into input IDs for the model.\n",
        "\n",
        "**Parameters**:\n",
        "- `example` (dict): A single example from the dataset containing source and target sentences.\n",
        "- `tokenizer`: Tokenizer object to convert text into model-readable input.\n",
        "- `**kwargs`: Additional arguments for the tokenizer.\n",
        "\n",
        "**Functionality**:\n",
        "1. Tokenizes the source sentence with truncation and padding.\n",
        "2. Tokenizes the target sentence using the tokenizer in target mode.\n",
        "3. Adds tokenized target input IDs as labels to the model inputs.\n",
        "\n",
        "**Returns**:  \n",
        "A dictionary containing tokenized inputs and labels.\n",
        "\n",
        "---\n",
        "\n",
        "### Notes\n",
        "- Ensure the `processor` and `tokenizer` are correctly initialized for your language pair before using these functions.\n",
        "- Missing source/target files or mismatched line counts will cause errors during dataset loading.\n",
        "\n"
      ],
      "metadata": {
        "id": "-5xlOEPdJHZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_translation_dataset(\n",
        "    data_dir,\n",
        "    split=\"train\",\n",
        "    tokenizer=None,\n",
        "    processor=None,\n",
        "    src_lang_list=None,\n",
        "    tgt_lang_list=None,\n",
        "    num_proc=None,\n",
        "    seed=42\n",
        "):\n",
        "    complete_dataset = {\n",
        "        \"sentence_SRC\": [],\n",
        "        \"sentence_TGT\": [],\n",
        "    }\n",
        "\n",
        "    for src_lang in src_lang_list:\n",
        "        for tgt_lang in tgt_lang_list:\n",
        "            if src_lang == tgt_lang:\n",
        "                continue\n",
        "            src_path = os.path.join(\n",
        "                data_dir, split, f\"{src_lang}-{tgt_lang}\", f\"{split}.{src_lang}\"\n",
        "            )\n",
        "            tgt_path = os.path.join(\n",
        "                data_dir, split, f\"{src_lang}-{tgt_lang}\", f\"{split}.{tgt_lang}\"\n",
        "            )\n",
        "            if not os.path.exists(src_path) or not os.path.exists(tgt_path):\n",
        "                raise FileNotFoundError(\n",
        "                    f\"Source ({split}.{src_lang}) or Target ({split}.{tgt_lang}) file not found in {data_dir}\"\n",
        "                )\n",
        "            with open(src_path, encoding=\"utf-8\") as src_file, open(\n",
        "                tgt_path, encoding=\"utf-8\"\n",
        "            ) as tgt_file:\n",
        "                src_lines = src_file.readlines()\n",
        "                tgt_lines = tgt_file.readlines()\n",
        "\n",
        "            # Ensure both files have the same number of lines\n",
        "            assert len(src_lines) == len(\n",
        "                tgt_lines\n",
        "            ), f\"Source and Target files have different number of lines for {split}.{src_lang} and {split}.{tgt_lang}\"\n",
        "\n",
        "            complete_dataset[\"sentence_SRC\"] += processor.preprocess_batch(\n",
        "                src_lines, src_lang=src_lang, tgt_lang=tgt_lang, is_target=False\n",
        "            )\n",
        "\n",
        "            complete_dataset[\"sentence_TGT\"] += processor.preprocess_batch(\n",
        "                tgt_lines, src_lang=tgt_lang, tgt_lang=src_lang, is_target=True\n",
        "            )\n",
        "\n",
        "    complete_dataset = Dataset.from_dict(complete_dataset).shuffle(seed=seed)\n",
        "\n",
        "    return complete_dataset.map(\n",
        "        lambda example: preprocess_fn(\n",
        "            example,\n",
        "            tokenizer=tokenizer\n",
        "        ),\n",
        "        batched=True,\n",
        "        num_proc=num_proc,\n",
        "    )\n",
        "\n",
        "\n",
        "def compute_metrics_factory(\n",
        "    tokenizer, metric_dict=None, print_samples=False, n_samples=10\n",
        "):\n",
        "    def compute_metrics(eval_preds):\n",
        "        preds, labels = eval_preds\n",
        "\n",
        "        labels[labels == -100] = tokenizer.pad_token_id\n",
        "        preds[preds == -100] = tokenizer.pad_token_id\n",
        "\n",
        "        with tokenizer.as_target_tokenizer():\n",
        "            preds = [\n",
        "                x.strip()\n",
        "                for x in tokenizer.batch_decode(\n",
        "                    preds, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
        "                )\n",
        "            ]\n",
        "            labels = [\n",
        "                x.strip()\n",
        "                for x in tokenizer.batch_decode(\n",
        "                    labels, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
        "                )\n",
        "            ]\n",
        "\n",
        "        assert len(preds) == len(\n",
        "            labels\n",
        "        ), \"Predictions and Labels have different lengths\"\n",
        "\n",
        "        df = pd.DataFrame({\"Predictions\": preds, \"References\": labels}).sample(\n",
        "            n=n_samples\n",
        "        )\n",
        "\n",
        "        if print_samples:\n",
        "            for pred, label in zip(df[\"Predictions\"].values, df[\"References\"].values):\n",
        "                print(f\" | > Prediction: {pred}\")\n",
        "                print(f\" | > Reference: {label}\\n\")\n",
        "\n",
        "        return {\n",
        "            metric_name: metric.corpus_score(preds, [labels]).score\n",
        "            for (metric_name, metric) in metric_dict.items()\n",
        "        }\n",
        "\n",
        "    return compute_metrics\n",
        "\n",
        "\n",
        "def preprocess_fn(example, tokenizer, **kwargs):\n",
        "    model_inputs = tokenizer(\n",
        "        example[\"sentence_SRC\"], truncation=True, padding=False, max_length=256\n",
        "    )\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            example[\"sentence_TGT\"], truncation=True, padding=False, max_length=256\n",
        "        )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "khKtGD7p4K9a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mount the drive"
      ],
      "metadata": {
        "id": "NBicNxvhJV19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZEkXHeg6W9R",
        "outputId": "fca752ef-b343-404a-ea58-ca4fdf15e730"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration\n"
      ],
      "metadata": {
        "id": "wNMcMMdfJexj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.model = \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
        "        self.src_lang_list = \"eng_Latn\"\n",
        "        self.tgt_lang_list = \"hin_Deva\"\n",
        "        self.data_dir = \"/content/drive/MyDrive/en-indic-exp\"\n",
        "        self.output_dir = \"/content/drive/MyDrive/output\"\n",
        "        self.save_steps = 100\n",
        "        self.eval_steps = 100\n",
        "        self.batch_size = 32\n",
        "        self.num_train_epochs = 100\n",
        "        self.max_steps = 100\n",
        "        self.grad_accum_steps = 4\n",
        "        self.warmup_steps = 4000\n",
        "        self.warmup_ratio = 0.0\n",
        "        self.max_grad_norm = 1.0\n",
        "        self.learning_rate = 5e-4\n",
        "        self.weight_decay = 0.0\n",
        "        self.adam_beta1 = 0.9\n",
        "        self.adam_beta2 = 0.98\n",
        "        self.dropout = 0.0\n",
        "        self.print_samples = True\n",
        "        self.optimizer = \"adamw_torch\"\n",
        "        self.lr_scheduler = \"inverse_sqrt\"\n",
        "        self.label_smoothing = 0.0\n",
        "        self.num_workers = 8\n",
        "        self.metric_for_best_model = \"eval_loss\"\n",
        "        self.greater_is_better = True\n",
        "        self.lora_target_modules = \"q_proj,k_proj\"\n",
        "        self.lora_dropout = 0.1\n",
        "        self.lora_r = 16\n",
        "        self.lora_alpha = 32\n",
        "        self.report_to = \"none\"\n",
        "        self.patience = 5\n",
        "        self.threshold = 1e-3\n",
        "\n",
        "args = Args()\n"
      ],
      "metadata": {
        "id": "vZ2uOf6S5FKE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Training and Evaluation Workflow\n",
        "\n",
        "The `main` function orchestrates the training and evaluation of the IndicTrans2 translation model using the provided arguments and configurations.\n",
        "\n",
        "---\n",
        "\n",
        "### Function: `main(args)`\n",
        "\n",
        "**Purpose**:  \n",
        "To load the model, tokenizer, datasets, and metrics, and to set up and train a sequence-to-sequence model with parameter-efficient fine-tuning (LoRA).\n",
        "\n",
        "---\n",
        "\n",
        "### Workflow\n",
        "\n",
        "#### 1. **Loading Model and Tokenizer**\n",
        "- Loads the pre-trained IndicTrans2 model specified by `args.model`.\n",
        "- Initializes the tokenizer for text preprocessing.\n",
        "- Prepares an `IndicProcessor` for language-specific preprocessing before tokenization.\n",
        "\n",
        "#### 2. **Data Collation**\n",
        "- Creates a data collation function (`IndicDataCollator`) to pad and prepare batches for training and evaluation.\n",
        "\n",
        "#### 3. **Dataset Preparation**\n",
        "- Loads and preprocesses the training and evaluation datasets using the `load_and_process_translation_dataset` function.\n",
        "- Handles missing data directory or files by raising errors.\n",
        "\n",
        "#### 4. **LoRA Configuration**\n",
        "- Configures LoRA fine-tuning with the specified parameters:\n",
        "  - `lora_r`, `lora_alpha`, and `lora_dropout` control the low-rank adaptation.\n",
        "  - `target_modules` specifies which modules in the model to fine-tune.\n",
        "\n",
        "#### 5. **Metrics Setup**\n",
        "- Initializes a metric computation factory using BLEU and chrF metrics to evaluate translation performance.\n",
        "\n",
        "#### 6. **Training Arguments**\n",
        "- Sets up training configurations using `Seq2SeqTrainingArguments`, including:\n",
        "  - Hyperparameters (learning rate, batch size, warmup steps).\n",
        "  - Optimization settings (`adam_beta1`, `adam_beta2`, weight decay).\n",
        "  - Evaluation and logging frequency.\n",
        "  - Mixed precision (`fp16`) for faster training.\n",
        "\n",
        "#### 7. **Trainer Initialization**\n",
        "- Creates a `Seq2SeqTrainer` instance with:\n",
        "  - Model, arguments, data collator, datasets, and metrics.\n",
        "  - An `EarlyStoppingCallback` to halt training based on patience and loss threshold.\n",
        "\n",
        "#### 8. **Training and Saving**\n",
        "- Trains the model and saves the LoRA adapter weights to `args.output_dir`.\n",
        "\n",
        "---\n",
        "\n",
        "### Key Features\n",
        "- **Fine-tuning with LoRA**: Efficient parameter tuning for sequence-to-sequence models.\n",
        "- **Dynamic Dataset Loading**: Supports multiple language pairs with validation.\n",
        "- **Metrics for Evaluation**: BLEU and chrF metrics for assessing translation quality.\n",
        "- **Early Stopping**: Prevents overfitting and conserves resources.\n",
        "\n",
        "---\n",
        "\n",
        "### Notes\n",
        "- Interrupting training with `Ctrl+C` saves progress up to the last checkpoint.\n",
        "- The model saves only the LoRA adapter weights, making the saved model lightweight and portable.\n",
        "\n"
      ],
      "metadata": {
        "id": "iDqBhuVGJv0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(args):\n",
        "    print(f\" | > Loading {args.model} and tokenizer ...\")\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "        args.model,\n",
        "        trust_remote_code=True,\n",
        "        attn_implementation=\"eager\",\n",
        "        dropout=args.dropout\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(args.model, trust_remote_code=True)\n",
        "    processor = IndicProcessor(inference=False) # pre-process before tokenization\n",
        "\n",
        "    data_collator = IndicDataCollator(\n",
        "        tokenizer=tokenizer,\n",
        "        model=model,\n",
        "        padding=\"longest\", # saves padding tokens\n",
        "        pad_to_multiple_of=8, # better to have it as 8 when using fp16\n",
        "        label_pad_token_id=-100\n",
        "    )\n",
        "\n",
        "    if args.data_dir is not None:\n",
        "        train_dataset = load_and_process_translation_dataset(\n",
        "            args.data_dir,\n",
        "            split=\"train\",\n",
        "            tokenizer=tokenizer,\n",
        "            processor=processor,\n",
        "            src_lang_list=args.src_lang_list.split(\",\"),\n",
        "            tgt_lang_list=args.tgt_lang_list.split(\",\"),\n",
        "        )\n",
        "        print(f\" | > Loaded train dataset from {args.data_dir}. Size: {len(train_dataset)} ...\")\n",
        "\n",
        "        eval_dataset = load_and_process_translation_dataset(\n",
        "            args.data_dir,\n",
        "            split=\"dev\",\n",
        "            tokenizer=tokenizer,\n",
        "            processor=processor,\n",
        "            src_lang_list=args.src_lang_list.split(\",\"),\n",
        "            tgt_lang_list=args.tgt_lang_list.split(\",\"),\n",
        "        )\n",
        "        print(f\" | > Loaded eval dataset from {args.data_dir}. Size: {len(eval_dataset)} ...\")\n",
        "    else:\n",
        "        raise ValueError(\" | > Data directory not provided\")\n",
        "\n",
        "    lora_config = LoraConfig(\n",
        "        r=args.lora_r,\n",
        "        bias=\"none\",\n",
        "        inference_mode=False,\n",
        "        task_type=\"SEQ_2_SEQ_LM\",\n",
        "        lora_alpha=args.lora_alpha,\n",
        "        lora_dropout=args.lora_dropout,\n",
        "        target_modules=args.lora_target_modules.split(\",\"),\n",
        "    )\n",
        "\n",
        "    model.set_label_smoothing(args.label_smoothing)\n",
        "\n",
        "    model = get_peft_model(model, lora_config)\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    print(f\" | > Loading metrics factory with BLEU and chrF ...\")\n",
        "    seq2seq_compute_metrics = compute_metrics_factory(\n",
        "        tokenizer=tokenizer,\n",
        "        print_samples=args.print_samples,\n",
        "        metric_dict={\"BLEU\": bleu_metric, \"chrF\": chrf_metric},\n",
        "    )\n",
        "\n",
        "    training_args = Seq2SeqTrainingArguments(\n",
        "        output_dir=args.output_dir,\n",
        "        do_train=True,\n",
        "        do_eval=True,\n",
        "        fp16=True, # use fp16 for faster training\n",
        "        logging_strategy=\"steps\",\n",
        "        evaluation_strategy=\"steps\",\n",
        "        save_strategy=\"steps\",\n",
        "        logging_steps=5,\n",
        "        save_total_limit=1,\n",
        "        predict_with_generate=True,\n",
        "        load_best_model_at_end=True,\n",
        "        max_steps=args.max_steps, # max_steps overrides num_train_epochs\n",
        "        per_device_train_batch_size=args.batch_size,\n",
        "        per_device_eval_batch_size=args.batch_size,\n",
        "        gradient_accumulation_steps=args.grad_accum_steps,\n",
        "        eval_accumulation_steps=args.grad_accum_steps,\n",
        "        weight_decay=args.weight_decay,\n",
        "        adam_beta1=args.adam_beta1,\n",
        "        adam_beta2=args.adam_beta2,\n",
        "        max_grad_norm=args.max_grad_norm,\n",
        "        optim=args.optimizer,\n",
        "        lr_scheduler_type=args.lr_scheduler,\n",
        "        warmup_ratio=args.warmup_ratio,\n",
        "        warmup_steps=args.warmup_steps,\n",
        "        learning_rate=args.learning_rate,\n",
        "        num_train_epochs=args.num_train_epochs,\n",
        "        save_steps=args.save_steps,\n",
        "        eval_steps=args.eval_steps,\n",
        "        dataloader_num_workers=args.num_workers,\n",
        "        metric_for_best_model=args.metric_for_best_model,\n",
        "        greater_is_better=args.greater_is_better,\n",
        "        report_to=args.report_to,\n",
        "        generation_max_length=256,\n",
        "        generation_num_beams=5,\n",
        "        sortish_sampler=True,\n",
        "        group_by_length=True,\n",
        "        include_tokens_per_second=True,\n",
        "        include_num_input_tokens_seen=True,\n",
        "        dataloader_prefetch_factor=2,\n",
        "    )\n",
        "\n",
        "    # Create Trainer instance\n",
        "    trainer = Seq2SeqTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        compute_metrics=seq2seq_compute_metrics,\n",
        "        callbacks=[\n",
        "            EarlyStoppingCallback(\n",
        "                early_stopping_patience=args.patience,\n",
        "                early_stopping_threshold=args.threshold,\n",
        "            )\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    print(f\" | > Starting training ...\")\n",
        "\n",
        "    try:\n",
        "        trainer.train()\n",
        "    except KeyboardInterrupt:\n",
        "        print(f\" | > Training interrupted ...\")\n",
        "\n",
        "    # this will only save the LoRA adapter weights\n",
        "    model.save_pretrained(args.output_dir)"
      ],
      "metadata": {
        "id": "tu5p0xAx4-Mx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    main(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865,
          "referenced_widgets": [
            "6aee3286d04f4053a4a0a2b3c620f847",
            "31b32a0dce10452e841d18da38db2715",
            "910c3ed5fc0c4edba6b041c1541f866f",
            "5e6016114c2a4542b9828743fcd21889",
            "19198321c52c4bef9fbaa77479787535",
            "fc033035b6bd4582b9e12b0d0760f748",
            "3d62496ea4bd4642bce5bdc1f8fd7034",
            "8a9653fe657643539c05251cee6295b9",
            "110da91eedd1404f94a8788f021ab435",
            "5a60660be0e948d4ad7075848a8e8b22",
            "0a586adfd2184e7b8b0ebe1d1da29a21",
            "ef425fa04a4e4483ac39f9532ed7848a",
            "30da68909f5c4452bdff461dab833e98",
            "d1c6ac28944448deb825ebedb0986549",
            "ed304b42534646fea1d73060fe84206f",
            "999687d5432f49c6afeab05602056e70",
            "cccc68ac13c74a31ba362e111e8a873c",
            "232c30df3360463ca05cb2c706d8b4d1",
            "4c704fbd278b47d3b66be63d790684ae",
            "eed1abc400da49e6bd2f590e674847b5",
            "4524a10e2f764ca98c7c77d69bfb9d6d",
            "dccad691c80049368ca56bca7327d62f"
          ]
        },
        "id": "8Ww9OXLb59I6",
        "outputId": "af6ec6e3-8a97-4b1f-a3bd-b5302b9190a4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Loading ai4bharat/indictrans2-en-indic-dist-200M and tokenizer ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6aee3286d04f4053a4a0a2b3c620f847"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Loaded train dataset from /content/drive/MyDrive/en-indic-exp. Size: 3 ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/520 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef425fa04a4e4483ac39f9532ed7848a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Loaded eval dataset from /content/drive/MyDrive/en-indic-exp. Size: 520 ...\n",
            "trainable params: 1,769,472 || all params: 276,354,048 || trainable%: 0.6403\n",
            " | > Loading metrics factory with BLEU and chrF ...\n",
            " | > Starting training ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 29:30, Epoch 100/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>Chrf</th>\n",
              "      <th>Input Tokens Seen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.777500</td>\n",
              "      <td>1.913523</td>\n",
              "      <td>24.456055</td>\n",
              "      <td>52.107819</td>\n",
              "      <td>16800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Prediction: लोगों को प्रेरित करते हुए बलवीर सिंह ने कहा कि अगर कोई अधिकारी या कर्मचारी किसी काम के लिए रिश्वत मांगता है तो सतर्कता विभाग को शिकायत भेजी जा सकती है ।\n",
            " | > Reference: लोगों को प्रेरित करते हुए कहा कि यदि कोई अधिकारी या कर्मचारी किसी भी काम के लिए रिश्वत की मांग करता है तो उसकी शिकायत विजिलेंस विभाग से की जा सकती है ।\n",
            "\n",
            " | > Prediction: कुछ टीवी द्वारा बनाए गए हैं और ज्यादातर राजनीतिक पूर्वाग्रह के साथ पक्षपाती हैं ।\n",
            " | > Reference: कुछ टीवी के गढ़े हुए और च्यादातर राजनीतिक पक्षपात से रंगे हुए ।\n",
            "\n",
            " | > Prediction: वे सभी नवीनीकरण और वैध ड्राइविंग लाइसेंस ( डी. एल. ) तैयार हैं जहां 30 सितंबर तक तस्वीरें जमा की गई हैं, बाकी अगले सप्ताह तक प्रदान कर दी जाएंगी ।\n",
            " | > Reference: रिन्युअल व पक्के ड्राइविंग लाइसेंस ( डीएल ) जिनकी फोटो 30 सितंबर तक हो चुकी है वह तैयार हो चुके हैं, बाकी लाइसेंस अगले सप्ताह मिलेंगे ।\n",
            "\n",
            " | > Prediction: इस वजह से तेज रफ्तार टैक्सी राजमार्ग के किनारे एक नीलगिरी के पेड़ से टकरा गई ।\n",
            " | > Reference: इससे तेज रफ्तार टैक्सी राजमार्ग के किनारे सफेदे के पेड़ से टकरा कर क्षतिग्रस्त हो गई ।\n",
            "\n",
            " | > Prediction: युवक के शरीर में गोली के दो घाव पाए गए ।\n",
            " | > Reference: युवक के शरीर पर गोली के दो निशान मिले हैं ।\n",
            "\n",
            " | > Prediction: जयपुर । यात्रियों की कमी के कारण, रेलवे प्रशासन ने ट्रेनों में कड़ी जांच शुरू कर दी है और इसके परिणामस्वरूप एक ही महीने में यात्रियों की संख्या बढ़कर 39,000 हो गई है ।\n",
            " | > Reference: जयपुर. ट्रेनों में यात्रियों की कमी से जूझ रहे रेलवे प्रशासन ने जब ट्रेनों की जांच का सघन अभियान चलाया तो एक महीने में ही यात्री संख्या 39 हजार बढ़ गई ।\n",
            "\n",
            " | > Prediction: इस दिन सोना, चांदी और बर्तनों की खरीदारी लोकप्रिय है ।\n",
            " | > Reference: इस दिन विशेष रूप से सोना - चांदी व बर्तनों की खरीददारी होती है ।\n",
            "\n",
            " | > Prediction: नियत तिथि के 15 दिन बाद कनेक्शन काट दिया जा रहा है ।\n",
            " | > Reference: तय तिथि के 15 दिन के बाद कनेक्शन काटे जा रहे हैं ।\n",
            "\n",
            " | > Prediction: निगम आंशिक भुगतान के रूप में बिल का 80 से 90 प्रतिशत भुगतान स्वीकार कर रहा है ।\n",
            " | > Reference: यदि निगम पार्ट पेमेंट ले रहा है तो उपभोक्ताओं को बिल का 80 से 90 प्रतिशत हिस्सा भरना पड़ रहा है ।\n",
            "\n",
            " | > Prediction: मूल रूप से, वह एटा के मलावन से आया था ।\n",
            " | > Reference: वह मूलरूप से एटा के मलावन के रहने वाले थे ।\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OWTbRhs26FlT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}